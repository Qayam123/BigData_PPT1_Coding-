{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25880907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: kafka-python\n",
      "Successfully installed kafka-python-2.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 1. a) Write a Python program to create a Kafka producer.\n",
    "!pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462bb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "\n",
    "def create_kafka_producer(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance\n",
    "    producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Convert the message to bytes and send it to the Kafka topic\n",
    "            producer.send(topic, value=message.encode(\"utf-8\"))\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server address and topic\n",
    "    kafka_server = \"localhost:9092\"\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    create_kafka_producer(kafka_server, kafka_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41696e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Configure the producer to connect to a Kafka cluster.\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def create_kafka_producer(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance with configuration\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: str(v).encode(\"utf-8\")  # Serialize values to bytes\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Send the message to the Kafka topic\n",
    "            producer.send(topic, value=message)\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"kafka-broker1:9092\", \"kafka-broker2:9092\", \"kafka-broker3:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    create_kafka_producer(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    " # c) Implement logic to send messages to a Kafka topic.\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def send_messages_to_kafka_topic(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance with configuration\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: str(v).encode(\"utf-8\")  # Serialize values to bytes\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Send the message to the Kafka topic\n",
    "            producer.send(topic, value=message)\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "            print(f\"Message sent to Kafka topic: {message}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"kafka-broker1:9092\", \"kafka-broker2:9092\", \"kafka-broker3:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    send_messages_to_kafka_topic(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfd53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 a) Write a Python program to create a Kafka consumer\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def create_kafka_consumer(bootstrap_servers, topic):\n",
    "    # Create a Kafka consumer instance\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=\"my-group\"  # Replace with your consumer group ID\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            # Decode the message value and print it\n",
    "            print(f\"Received message: {message.value.decode('utf-8')}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the consumer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server address and topic\n",
    "    kafka_server = \"localhost:9092\"\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    create_kafka_consumer(kafka_server, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure the consumer to connect to a Kafka cluster.\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def create_kafka_consumer(bootstrap_servers, topic):\n",
    "    # Create a Kafka consumer instance with configuration\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=\"my-group\",  # Replace with your consumer group ID\n",
    "        auto_offset_reset=\"earliest\",  # Set to 'earliest' to read from the beginning of the topic\n",
    "        enable_auto_commit=True,  # Auto-commit offsets after processing messages\n",
    "        value_deserializer=lambda v: v.decode(\"utf-8\")  # Deserialize values from bytes to strings\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            # Print the message value\n",
    "            print(f\"Received message: {message.value}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the consumer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"kafka-broker1:9092\", \"kafka-broker2:9092\", \"kafka-broker3:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    create_kafka_consumer(kafka_servers, kafka_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7dc6a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBrokersAvailable",
     "evalue": "NoBrokersAvailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18278/3721625031.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mkafka_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"your_topic_here\"\u001b[0m  \u001b[0;31m# Replace with your Kafka topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mconsume_messages_from_kafka_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkafka_servers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkafka_topic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18278/3721625031.py\u001b[0m in \u001b[0;36mconsume_messages_from_kafka_topic\u001b[0;34m(bootstrap_servers, topic)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconsume_messages_from_kafka_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap_servers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Create a Kafka consumer instance with configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     consumer = KafkaConsumer(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbootstrap_servers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_servers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/kafka/consumer/group.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *topics, **configs)\u001b[0m\n\u001b[1;32m    354\u001b[0m                         str(self.config['api_version']), str_version)\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKafkaClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# Get auto-discovered version from client if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **configs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mcheck_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version_auto_timeout_ms'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'api_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_can_bootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/kafka/client_async.py\u001b[0m in \u001b[0;36mcheck_version\u001b[0;34m(self, node_id, timeout, strict)\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtry_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoBrokersAvailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtry_node\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoBrokersAvailable\u001b[0m: NoBrokersAvailable"
     ]
    }
   ],
   "source": [
    "#Implement logic to consume messages from a Kafka topic.\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def consume_messages_from_kafka_topic(bootstrap_servers, topic):\n",
    "    # Create a Kafka consumer instance with configuration\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=\"my-group\",  # Replace with your consumer group ID\n",
    "        auto_offset_reset=\"earliest\",  # Set to 'earliest' to read from the beginning of the topic\n",
    "        enable_auto_commit=True,  # Auto-commit offsets after processing messages\n",
    "        value_deserializer=lambda v: v.decode(\"utf-8\")  # Deserialize values from bytes to strings\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            # Process the message value\n",
    "            print(f\"Received message: {message.value}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the consumer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"kafka-broker1:9092\", \"kafka-broker2:9092\", \"kafka-broker3:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    consume_messages_from_kafka_topic(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd507c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent-kafka\n",
      "  Downloading confluent_kafka-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-2.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#3.a> Write a Python program to create a new Kafka topic.\n",
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07804a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "def create_kafka_topic(bootstrap_servers, topic_name, partitions=1, replication_factor=1):\n",
    "    # Create an AdminClient with the Kafka broker addresses\n",
    "    admin_client = AdminClient({\"bootstrap.servers\": bootstrap_servers})\n",
    "\n",
    "    # Create the new topic configuration\n",
    "    new_topic = NewTopic(topic_name, num_partitions=partitions, replication_factor=replication_factor)\n",
    "\n",
    "    # Call the create_topics method to create the topic\n",
    "    admin_client.create_topics([new_topic])\n",
    "\n",
    "    print(f\"Topic '{topic_name}' created successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic details\n",
    "    kafka_servers = \"localhost:9092\"\n",
    "    kafka_topic_name = \"new_topic\"  # Replace with your desired topic name\n",
    "    num_partitions = 3\n",
    "    replication_factor = 2\n",
    "\n",
    "    create_kafka_topic(kafka_servers, kafka_topic_name, num_partitions, replication_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961babff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.b Implement functionality to list existing topics.\n",
    "from confluent_kafka.admin import AdminClient\n",
    "\n",
    "def list_kafka_topics(bootstrap_servers):\n",
    "    # Create an AdminClient with the Kafka broker addresses\n",
    "    admin_client = AdminClient({\"bootstrap.servers\": bootstrap_servers})\n",
    "\n",
    "    # Call the list_topics method to retrieve the existing topics\n",
    "    topics_metadata = admin_client.list_topics(timeout=10)\n",
    "\n",
    "    # Extract the topic names from the topics_metadata response\n",
    "    topic_names = list(topics_metadata.topics.keys())\n",
    "\n",
    "    return topic_names\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses\n",
    "    kafka_servers = \"localhost:9092\"\n",
    "\n",
    "    # Get the list of existing topics\n",
    "    existing_topics = list_kafka_topics(kafka_servers)\n",
    "\n",
    "    # Print the list of existing topics\n",
    "    print(\"Existing Kafka Topics:\")\n",
    "    for topic in existing_topics:\n",
    "        print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Develop logic to delete an existing Kafka topic\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "def delete_kafka_topic(bootstrap_servers, topic_name):\n",
    "    # Create an AdminClient with the Kafka broker addresses\n",
    "    admin_client = AdminClient({\"bootstrap.servers\": bootstrap_servers})\n",
    "\n",
    "    # Call the delete_topics method to delete the topic\n",
    "    delete_result = admin_client.delete_topics([topic_name], operation_timeout=30)\n",
    "\n",
    "    # Check the result of the topic deletion\n",
    "    for topic, future in delete_result.items():\n",
    "        try:\n",
    "            future.result()\n",
    "            print(f\"Topic '{topic}' deleted successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete topic '{topic}': {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic details\n",
    "    kafka_servers = \"localhost:9092\"\n",
    "    kafka_topic_name = \"your_topic_here\"  # Replace with the topic you want to delete\n",
    "\n",
    "    delete_kafka_topic(kafka_servers, kafka_topic_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.aWrite a Python program to produce messages to a Kafka topic.\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def produce_messages_to_kafka_topic(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance with configuration\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: str(v).encode(\"utf-8\")  # Serialize values to bytes\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Send the message to the Kafka topic\n",
    "            producer.send(topic, value=message)\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    produce_messages_to_kafka_topic(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.b Implement logic to consume messages from the same Kafka topic.\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def produce_messages_to_kafka_topic(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance with configuration\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: str(v).encode(\"utf-8\")  # Serialize values to bytes\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Send the message to the Kafka topic\n",
    "            producer.send(topic, value=message)\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    produce_messages_to_kafka_topic(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.c Test the end-to-end flow of message production and consumption.\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def produce_messages_to_kafka_topic(bootstrap_servers, topic):\n",
    "    # Create a Kafka producer instance with configuration\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_serializer=lambda v: str(v).encode(\"utf-8\")  # Serialize values to bytes\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Get the message from the user\n",
    "            message = input(\"Enter message (or type 'exit' to quit): \")\n",
    "            if message.lower() == \"exit\":\n",
    "                break\n",
    "\n",
    "            # Send the message to the Kafka topic\n",
    "            producer.send(topic, value=message)\n",
    "\n",
    "            # Flush to ensure the message is sent immediately\n",
    "            producer.flush()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the producer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the producer connection when done\n",
    "        producer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses and topic\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "\n",
    "    produce_messages_to_kafka_topic(kafka_servers, kafka_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e402e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.a Write a Python program to create a Kafka consumer within a consumer group.\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def create_kafka_consumer(bootstrap_servers, topic, group_id):\n",
    "    # Create a Kafka consumer instance with configuration\n",
    "    consumer = KafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=group_id,\n",
    "        auto_offset_reset='earliest',  # Start consuming from the beginning of the topic\n",
    "        value_deserializer=lambda v: v.decode('utf-8')  # Deserialize values from bytes to strings\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for message in consumer:\n",
    "            # Process the message value\n",
    "            print(f\"Consumer '{group_id}' received: {message.value}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the consumer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses, topic, and consumer group ID\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "    consumer_group = \"my-consumer-group\"  # Replace with your desired consumer group ID\n",
    "\n",
    "    create_kafka_consumer(kafka_servers, kafka_topic, consumer_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f82893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.b Implement logic to handle messages consumed by different consumers within the same group.\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "\n",
    "def consume_messages_within_group(bootstrap_servers, topic, group_id):\n",
    "    # Create a Kafka consumer instance with configuration\n",
    "    consumer = KafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=group_id,\n",
    "        auto_offset_reset='earliest',  # Start consuming from the beginning of the topic\n",
    "        value_deserializer=lambda v: v.decode('utf-8')  # Deserialize values from bytes to strings\n",
    "    )\n",
    "\n",
    "    # Subscribe to the topic\n",
    "    consumer.subscribe(topics=[topic])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Consume messages for the assigned partitions\n",
    "            for message in consumer:\n",
    "                # Process the message value\n",
    "                print(f\"Consumer '{group_id}' received: {message.value}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt: Stopping the consumer.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses, topic, and consumer group ID\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "    consumer_group = \"my-consumer-group\"  # Replace with your desired consumer group ID\n",
    "\n",
    "    consume_messages_within_group(kafka_servers, kafka_topic, consumer_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37475563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.c Observe the behavior of consumer group rebalancing when adding or removing consumers.\n",
    "import time\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "def consume_messages_within_group(bootstrap_servers, topic, group_id):\n",
    "    # Create a Kafka consumer instance with configuration\n",
    "    consumer = KafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        group_id=group_id,\n",
    "        auto_offset_reset='earliest',  # Start consuming from the beginning of the topic\n",
    "        value_deserializer=lambda v: v.decode('utf-8')  # Deserialize values from bytes to strings\n",
    "    )\n",
    "\n",
    "    # Subscribe to the topic\n",
    "    consumer.subscribe(topics=[topic])\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Consume messages for the assigned partitions\n",
    "            for message in consumer:\n",
    "                # Process the message value\n",
    "                print(f\"Consumer '{group_id}' received: {message.value}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Consumer '{group_id}' is stopping.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer connection when done\n",
    "        consumer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the Kafka server addresses, topic, and consumer group ID\n",
    "    kafka_servers = [\"localhost:9092\"]\n",
    "    kafka_topic = \"your_topic_here\"  # Replace with your Kafka topic\n",
    "    consumer_group = \"my-consumer-group\"\n",
    "\n",
    "    # Start multiple consumers within the same consumer group\n",
    "    num_consumers = 3\n",
    "    consumers = []\n",
    "    for i in range(num_consumers):\n",
    "        consumer_id = f\"consumer-{i+1}\"\n",
    "        print(f\"Starting {consumer_id}...\")\n",
    "        consume_messages_within_group(kafka_servers, kafka_topic, consumer_group)\n",
    "        time.sleep(1)  # Add a small delay to avoid concurrent startup issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
